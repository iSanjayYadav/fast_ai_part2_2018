{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change to wherever the following files are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('../data/pascal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bb = V(np.load(PATH/'pred_bb.npy'))\n",
    "pred_cls = V(np.load(PATH/'pred_cls.npy'))\n",
    "targ_bb = V(np.load(PATH/'targ_bb.npy'))\n",
    "targ_cls = V(np.load(PATH/'targ_cls.npy'))\n",
    "overlaps0 = np.load(PATH/'overlaps0.npy')\n",
    "overlaps4 = np.load(PATH/'overlaps4.npy')\n",
    "size = 224\n",
    "nb_classes = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pred_bb,pred_cls contains the predictions for a mini-batch, given by the first model with 16 anchors. targ_bb, targ_cls contain the associated target of the mini-batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal: Completely rewrite the loss function.** \n",
    "- Final loss for the minibatch 15.6527\n",
    "- Idx 0 of our minibatch:\n",
    "  - ground truth classes to find: [20,20,20,20,20,20,20,20,14,20,1,20,20,20,14,20]\n",
    "  - cls loss 0.3888\n",
    "  - bb loss 0.1656\n",
    "- Idx 4 of our minibatch:\n",
    "  - ground truth classes to find: [20,14,14,20,20,20,4,20,20,20,14,20,20,20,14,4]\n",
    "  - cls loss 0.7884\n",
    "  - bb loss 0.1239"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plan:**\n",
    "1. Define the anchors (the 4 by 4 grid to begin with)\n",
    "2. Define the functions to compute the overlaps between our ground truth objects and the anchors\n",
    "3. Attribute a ground truth object to each anchor\n",
    "4. Compute the loss for the predicted classes\n",
    "5. Compute the loss for the predicted bboxes\n",
    "6. Sum over the minibatch\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the anchors then the predicted bboxes, coordinates vary between 0 and 1. We'll scale the target bboxes accordingly later.\n",
    "\n",
    "First let's get the centers of our anchors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anc_ctrs(n_split):\n",
    "    offset = 1/(2*n_split)\n",
    "    x_coords = np.array([offset + i/n_split for i in range(n_split)] * n_split)\n",
    "    y_coords = np.concatenate([[offset + i/n_split] * n_split for i in range(n_split)])\n",
    "    return np.array([x_coords,y_coords]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.125, 0.125],\n",
       "       [0.375, 0.125],\n",
       "       [0.625, 0.125],\n",
       "       [0.875, 0.125],\n",
       "       [0.125, 0.375],\n",
       "       [0.375, 0.375],\n",
       "       [0.625, 0.375],\n",
       "       [0.875, 0.375],\n",
       "       [0.125, 0.625],\n",
       "       [0.375, 0.625],\n",
       "       [0.625, 0.625],\n",
       "       [0.875, 0.625],\n",
       "       [0.125, 0.875],\n",
       "       [0.375, 0.875],\n",
       "       [0.625, 0.875],\n",
       "       [0.875, 0.875]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_split = 4\n",
    "anc_ctrs = get_anc_ctrs(n_split); anc_ctrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(anc_ctrs[:,0],anc_ctrs[:,1])\n",
    "plt.xlim(xmin=0,xmax=1)\n",
    "plt.ylim(ymin=0,ymax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loooking good. All the anchors will have the same height and width here, let's write a function to transform change center/size into top-left corner/bottom-right corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc_ctrs = V(anc_ctrs, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cs_to_crnrs(ctr,sz):\n",
    "    return torch.cat([ctr-sz/2,ctr+sz/2], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc_sz = V(np.array([[1/n_split,1/n_split]] * (n_split**2)), requires_grad=False)\n",
    "anc_crnrs = cs_to_crnrs(anc_ctrs,anc_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.0000  0.0000  0.2500  0.2500\n",
       " 0.2500  0.0000  0.5000  0.2500\n",
       " 0.5000  0.0000  0.7500  0.2500\n",
       " 0.7500  0.0000  1.0000  0.2500\n",
       " 0.0000  0.2500  0.2500  0.5000\n",
       " 0.2500  0.2500  0.5000  0.5000\n",
       " 0.5000  0.2500  0.7500  0.5000\n",
       " 0.7500  0.2500  1.0000  0.5000\n",
       " 0.0000  0.5000  0.2500  0.7500\n",
       " 0.2500  0.5000  0.5000  0.7500\n",
       " 0.5000  0.5000  0.7500  0.7500\n",
       " 0.7500  0.5000  1.0000  0.7500\n",
       " 0.0000  0.7500  0.2500  1.0000\n",
       " 0.2500  0.7500  0.5000  1.0000\n",
       " 0.5000  0.7500  0.7500  1.0000\n",
       " 0.7500  0.7500  1.0000  1.0000\n",
       "[torch.cuda.FloatTensor of size 16x4 (GPU 0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anc_crnrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our 16 anchors!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the function to compute the overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Write a function taking two arrays bb1 and bb2 representing bboxes of size n x 4 and p x 4 respectively, returning an array of siz n x p containing in coordinate (i,j) the jaccard index (or IoU) of the i-th bbox in bb1 and the j-th bbox in bb2.\n",
    "\n",
    "**To test:** The arrays overlaps0 (resp. overlaps4) contain the intended result for anc_crnrs and bb_targ[0] (resp. bb_targ[4]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's look at what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPQAAADuCAYAAAAOYioDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAA6NJREFUeJzt3UFOLDcARdFyxBL4Y9f+1wJ7qBone3CGGf0AX12q5nLO2LKekC6y1Igea60NaPjr7gHA4wgaQgQNIYKGEEFDiKAhRNAQImgIETSEvHzl8Ovr69r3/aIpwO+8v7//s9b69dG5LwW97/v29vb256uAPzLGOD9zzpMbQgQNIYKGEEFDiKAhRNAQImgIETSEfOkPSz5r3/ftPD/1OThPYM65Hcdx9wwe4JKgz/Pc/PPB72OMcfcEHsSTG0IEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAh5uXtA3b7v23med8/40Bjj7gk/0pxzO47jYfcJ+mLneW5rrbtn/K8xxtNvrHr0L1JPbggRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIebni0jnnNsa44upv6dl/FnPOuyfwIJcEfRzHFdd+S2OMba119wx+CE9uCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAh5JLvh+Y/c86n/8J37jPnfOh9gr7YcRx3T+AH8eSGEEFDiKAhRNAQImgIETSECBpCBA0hY631+cNj/L1t23ndHOA35lrr10eHvhQ08Nw8uSFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIeRfpJc/kxR57i4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "box1 = [0,0,10,8] ; box2 = [3,5,12,15]\n",
    "fig,ax = plt.subplots(figsize=(4,4))\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.yaxis.set_visible(False)\n",
    "ax.invert_yaxis() #To have the top at pixel 0 like in our images.\n",
    "\n",
    "def draw_rect(ax,box,fill=False):\n",
    "    ax.add_patch(patches.Rectangle((box[1],box[0]),box[3]-box[1],box[2]-box[0],fill=fill))\n",
    "\n",
    "draw_rect(ax,box1)\n",
    "draw_rect(ax,box2)\n",
    "ax.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to compute the number of pixels in the intersection and the union of the two boxes. The intersection is a rectangle, so that'll be easy once we know its width and height. The union has the size of the first box, plus the size of the second box minus the size of the intersection (since those pixels were counted twice).\n",
    "\n",
    "Top-left corner of our intersection has the maximum coordinates between the two top-left corners, bottom-right corner the minimum coordinates between the two bottom-right corners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPQAAADuCAYAAAAOYioDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAA7tJREFUeJzt3TFuFEkAhtEu5HwTI8KaA3EfzsB9OIZ9h56U3Ygc1YZEYBtNq+3P78Wl0p98o5LG8oy11gY0fDh7AHA7goYQQUOIoCFE0BAiaAgRNIQIGkIEDSF3Lzl8f3+/LpfLQVOA33l8fPxvrfXxqXMvCvpyuWwPDw9/vwr4K2OM63POeXJDiKAhRNAQImgIETSECBpCBA0hgoaQF/1hyXNdLpften3W9+C8AnPObd/3s2dwA4cEfb1eN/988O0YY5w9gRvx5IYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpC7s4eUHf3z6ft54/vZ8940hjj7Anv0pxz2/f9ZvcJ+mA/f3zf5pdvZ8/4o+vXz9ta6+wZ79KtP0g9uSFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAh5O6IS+ec2xjjiKvfpOvXz2dP+KM559kTuJFDgt73/Yhr36QxxrbWOnsG74QnN4QIGkIEDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIYKGEEFDiKAhRNAQImgIETSECBpCBA0hgoYQQUOIoCFE0BAiaAgRNIQIGkIEDSGChhBBQ4igIUTQEHLI70Pzy5xzG2OcPYNXas550/sEfbB938+ewDviyQ0hgoYQQUOIoCFE0BAiaAgRNIQIGkLGWuv5h8f4d9u263FzgN+Ya62PTx16UdDA6+bJDSGChhBBQ4igIUTQECJoCBE0hAgaQgQNIf8Dc5lBfK+uXz8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "box_inter = np.concatenate([np.maximum(box1[:2],box2[:2]), np.minimum(box1[2:],box2[2:])])\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(4,4))\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.yaxis.set_visible(False)\n",
    "ax.invert_yaxis() #To have the top at pixel 0 like our images.\n",
    "draw_rect(ax,box_inter,fill=True)\n",
    "draw_rect(ax,box1)\n",
    "draw_rect(ax,box2)\n",
    "ax.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same thing with tensors of boxes. We'll have to add dimensions since we want the final result to be of size n x p. To do that, we transform box1 in a tensor of size n x 1 x 4, box 2 in a tensor of size 1 x p x 4 so that what we did for two boxes will easily be broadcasted to the tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(box1,box2):\n",
    "    inter_top_crnrs = torch.max(box1[:,None,:2], box2[None,:,:2])\n",
    "    inter_btm_crnrs = torch.min(box1[:,None,2:], box2[None,:,2:])\n",
    "    inter_sizes = torch.clamp(inter_btm_crnrs - inter_top_crnrs,min=0) #In case two boxes don't overlap.\n",
    "    return inter_sizes[:,:,0] * inter_sizes[:,:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 12 \n",
       "    0     0     0     0     0     0     0     0     0     0     0     0   392\n",
       "    0     0     0     0     0     0     0     0     0     0     0   189   392\n",
       "    0     0     0     0     0     0     0     0     0     0     0   504   392\n",
       "    0     0     0     0     0     0     0     0     0     0     0   495   266\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0  3136\n",
       "    0     0     0     0     0     0     0     0     0     0     0  1176  3136\n",
       "    0     0     0     0     0     0     0     0     0     0     0  3136  3136\n",
       "    0     0     0     0     0     0     0     0     0     0     0  3080  2128\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0  3136\n",
       "    0     0     0     0     0     0     0     0     0     0     0  1176  3136\n",
       "    0     0     0     0     0     0     0     0     0     0     0  3136  3136\n",
       "    0     0     0     0     0     0     0     0     0     0     0  3080  2128\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0   728\n",
       "    0     0     0     0     0     0     0     0     0     0     0    42   728\n",
       "    0     0     0     0     0     0     0     0     0     0     0   112   728\n",
       "    0     0     0     0     0     0     0     0     0     0     0   110   494\n",
       "\n",
       "Columns 13 to 13 \n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       " 2491\n",
       " 2968\n",
       " 2968\n",
       " 2597\n",
       "[torch.cuda.FloatTensor of size 16x14 (GPU 0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection(anc_crnrs*224,targ_bb[0].view(-1,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the sizes of one array of bboxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sizes(bb):\n",
    "    return (bb[:,2] - bb[:,0]) * (bb[:,3] - bb[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then there's just to compute the union with the formula above and make the quotient. Let's just remember the sizes of bb1 will be a tensor of size (n) and the sizes of bb2 a tensor of size (p) so again, we have to brodcast by adding a dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(bb1,bb2):\n",
    "    inter = intersection(bb1,bb2)\n",
    "    union = get_sizes(bb1)[:,None] + get_sizes(bb2)[None,:] - inter\n",
    "    return inter / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 9 \n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0099  0.0267  0.0262  0.0000  0.0646  0.1932  0.1890  0.0000  0.0646\n",
       " 0.0131  0.0131  0.0131  0.0088  0.1153  0.1153  0.1153  0.0755  0.1153  0.1153\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 10 to 15 \n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.1932  0.1890  0.0000  0.0022  0.0058  0.0057\n",
       " 0.1153  0.0755  0.0246  0.0246  0.0246  0.0166\n",
       " 0.0000  0.0000  0.2135  0.2652  0.2652  0.2246\n",
       "[torch.cuda.FloatTensor of size 14x16 (GPU 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard(targ_bb[0].view(-1,4)/224,anc_crnrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should match overlaps0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.     , 0.00985, 0.02671, 0.02622, 0.     , 0.06463, 0.19315, 0.18905, 0.     , 0.06463, 0.19315,\n",
       "        0.18905, 0.     , 0.00217, 0.00582, 0.00571],\n",
       "       [0.01309, 0.01309, 0.01309, 0.00885, 0.11533, 0.11533, 0.11533, 0.07546, 0.11533, 0.11533, 0.11533,\n",
       "        0.07546, 0.02459, 0.02459, 0.02459, 0.01656],\n",
       "       [0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
       "        0.     , 0.21347, 0.26519, 0.26519, 0.2246 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlaps0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost! The problem is that we didn't suppress the zeros we used to pad the target to a size of 56 = 14x4. Why 14? It's the maximum of objects to detect in a single image in our sets so the fastai library padded up to this.\n",
    "\n",
    "Let's write this function to unpad the class and the bboxes of our targets. To detect those, we must remove the lines that are filled with zeros. It's not obvious in the class tensor (since the category 0 exists) but it is in the bboxes tensor. Since a line corresponding to a box has only positive numbers, I chose to sum over the lines to pick the ones that are filled with 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpad(t_cls,t_bb):\n",
    "    t_bb = t_bb.view(-1,4) / size\n",
    "    keep = t_bb.sum(dim=1).nonzero()[:,0]\n",
    "    return t_cls[keep], t_bb[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 9 \n",
       " 0.0000  0.0099  0.0267  0.0262  0.0000  0.0646  0.1932  0.1890  0.0000  0.0646\n",
       " 0.0131  0.0131  0.0131  0.0088  0.1153  0.1153  0.1153  0.0755  0.1153  0.1153\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 10 to 15 \n",
       " 0.1932  0.1890  0.0000  0.0022  0.0058  0.0057\n",
       " 0.1153  0.0755  0.0246  0.0246  0.0246  0.0166\n",
       " 0.0000  0.0000  0.2135  0.2652  0.2652  0.2246\n",
       "[torch.cuda.FloatTensor of size 3x16 (GPU 0)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_cls, t_bb = unpad(targ_cls[0],targ_bb[0])\n",
    "jaccard(t_bb,anc_crnrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.     , 0.00985, 0.02671, 0.02622, 0.     , 0.06463, 0.19315, 0.18905, 0.     , 0.06463, 0.19315,\n",
       "        0.18905, 0.     , 0.00217, 0.00582, 0.00571],\n",
       "       [0.01309, 0.01309, 0.01309, 0.00885, 0.11533, 0.11533, 0.11533, 0.07546, 0.11533, 0.11533, 0.11533,\n",
       "        0.07546, 0.02459, 0.02459, 0.02459, 0.01656],\n",
       "       [0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
       "        0.     , 0.21347, 0.26519, 0.26519, 0.2246 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlaps0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 9 \n",
       " 0.2042  0.3218  0.1917  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0257  0.2124  0.2124  0.2033  0.0119  0.0896  0.0896  0.0861  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.1507  0.2558  0.2558  0.2444  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0210  0.0305  0.0305  0.0294  0.1305  0.1987\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0865  0.0414  0.0000  0.0000\n",
       "\n",
       "Columns 10 to 15 \n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.1987  0.1902  0.0232  0.0337  0.0337  0.0324\n",
       " 0.0000  0.0000  0.1934  0.2526  0.2526  0.2414\n",
       " 0.0000  0.0481  0.0000  0.0000  0.0000  0.0583\n",
       " 0.0414  0.0203  0.0000  0.0000  0.0000  0.0000\n",
       "[torch.cuda.FloatTensor of size 7x16 (GPU 0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_cls, t_bb = unpad(targ_cls[4],targ_bb[4])\n",
    "jaccard(t_bb,anc_crnrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20419, 0.32184, 0.19171, 0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
       "        0.     , 0.     , 0.     , 0.     , 0.     ],\n",
       "       [0.02567, 0.21238, 0.21238, 0.20326, 0.01189, 0.08959, 0.08959, 0.08612, 0.     , 0.     , 0.     ,\n",
       "        0.     , 0.     , 0.     , 0.     , 0.     ],\n",
       "       [0.     , 0.     , 0.     , 0.     , 0.15067, 0.25579, 0.25579, 0.24442, 0.     , 0.     , 0.     ,\n",
       "        0.     , 0.     , 0.     , 0.     , 0.     ],\n",
       "       [0.     , 0.     , 0.     , 0.     , 0.02105, 0.0305 , 0.0305 , 0.02938, 0.13049, 0.19867, 0.19867,\n",
       "        0.19022, 0.0232 , 0.03365, 0.03365, 0.03241],\n",
       "       [0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
       "        0.     , 0.19336, 0.25257, 0.25257, 0.24137],\n",
       "       [0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
       "        0.04808, 0.     , 0.     , 0.     , 0.05825],\n",
       "       [0.     , 0.     , 0.     , 0.     , 0.     , 0.     , 0.08646, 0.04144, 0.     , 0.     , 0.04144,\n",
       "        0.0203 , 0.     , 0.     , 0.     , 0.     ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlaps4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mission accomplished!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute a ground truth object to each anchor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** After computing the overlaps between our anchors and the ground truth bboxes, we need to decide of a mapping between each anchor and a ground truth object. The rules for this are the following:\n",
    "1. For each ground truth object, attribute the anchor with the maximum overlap to it.\n",
    "2. Then, to each anchor remaining, attribute the ground truth object it overlaps the most. If this maximum is less than a fixed parameter (0.4 in the notebook), attribute it to background instead.\n",
    "\n",
    "**To test:** Compare the categories of ground truth object each anchors was given for sample 0 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play with an overlaps tensor before writing the functions we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_cls, t_bb = unpad(targ_cls[0],targ_bb[0])\n",
    "overlaps = jaccard(t_bb,anc_crnrs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 9 \n",
       " 0.0000  0.0099  0.0267  0.0262  0.0000  0.0646  0.1932  0.1890  0.0000  0.0646\n",
       " 0.0131  0.0131  0.0131  0.0088  0.1153  0.1153  0.1153  0.0755  0.1153  0.1153\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 10 to 15 \n",
       " 0.1932  0.1890  0.0000  0.0022  0.0058  0.0057\n",
       " 0.1153  0.0755  0.0246  0.0246  0.0246  0.0166\n",
       " 0.0000  0.0000  0.2135  0.2652  0.2652  0.2246\n",
       "[torch.cuda.FloatTensor of size 3x16 (GPU 0)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  0.1932\n",
       "  0.1153\n",
       "  0.2652\n",
       " [torch.cuda.FloatTensor of size 3 (GPU 0)], Variable containing:\n",
       "  10\n",
       "   8\n",
       "  14\n",
       " [torch.cuda.LongTensor of size 3 (GPU 0)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlaps.max(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the first ground truth object should be mapped to the 10th anchor (maximum overlap of 0.1932), the second ground truth object to the 8th anchor and the last one to the 14th anchor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  0.0131\n",
       "  0.0131\n",
       "  0.0267\n",
       "  0.0262\n",
       "  0.1153\n",
       "  0.1153\n",
       "  0.1932\n",
       "  0.1890\n",
       "  0.1153\n",
       "  0.1153\n",
       "  0.1932\n",
       "  0.1890\n",
       "  0.2135\n",
       "  0.2652\n",
       "  0.2652\n",
       "  0.2246\n",
       " [torch.cuda.FloatTensor of size 16 (GPU 0)], Variable containing:\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  2\n",
       "  2\n",
       "  2\n",
       "  2\n",
       " [torch.cuda.LongTensor of size 16 (GPU 0)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlaps.max(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then in all the remaining anchors, not one overlaps any ground truth object with more than 0.4 so they should be attributed to background.\n",
    "\n",
    "Here is the function that takes a tensor of ground truth bboxes and returns a tensor giving, for each anchor, the number of the ground truth object it should be mapped to, -1 if it should be mapped to background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(t_bb):\n",
    "    overlaps = jaccard(t_bb,anc_crnrs)\n",
    "    over_max,idx_max = overlaps.max(dim=0)\n",
    "    _,forced_idx = overlaps.max(dim=1)\n",
    "    over_max[forced_idx] = 1.1 #Any value greater than 1.\n",
    "    for i,o in enumerate(forced_idx): \n",
    "        idx_max[o] = i\n",
    "    idx_max[over_max <= 0.4] = -1\n",
    "    return idx_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       "-1\n",
       " 1\n",
       "-1\n",
       " 0\n",
       "-1\n",
       "-1\n",
       "-1\n",
       " 2\n",
       "-1\n",
       "[torch.cuda.LongTensor of size 16 (GPU 0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_cls, t_bb = unpad(targ_cls[0],targ_bb[0])\n",
    "match(t_bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good. Now the next step is to match the category of the ground truth object with this anchor, when it's not background. This just needs a minor tweak in the previous function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_cat(t_c,t_bb):\n",
    "    overlaps = jaccard(t_bb,anc_crnrs)\n",
    "    over_max,idx_max = overlaps.max(dim=0)\n",
    "    _,forced_idx = overlaps.max(dim=1)\n",
    "    over_max[forced_idx] = 1.1 #Any value greater than 1.\n",
    "    for i,o in enumerate(forced_idx): \n",
    "        idx_max[o] = i\n",
    "    cats = t_c[idx_max]\n",
    "    to_bg = over_max <= 0.4\n",
    "    idx_max[to_bg] = -1\n",
    "    cats[to_bg] = nb_classes\n",
    "    return idx_max, cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       "  1\n",
       " -1\n",
       "  0\n",
       " -1\n",
       " -1\n",
       " -1\n",
       "  2\n",
       " -1\n",
       " [torch.cuda.LongTensor of size 16 (GPU 0)], Variable containing:\n",
       "  20\n",
       "  20\n",
       "  20\n",
       "  20\n",
       "  20\n",
       "  20\n",
       "  20\n",
       "  20\n",
       "  14\n",
       "  20\n",
       "   1\n",
       "  20\n",
       "  20\n",
       "  20\n",
       "  14\n",
       "  20\n",
       " [torch.cuda.LongTensor of size 16 (GPU 0)])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_cls, t_bb = unpad(targ_cls[0],targ_bb[0])\n",
    "match_cat(t_cls,t_bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! Now ket's check the 4-th element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " -1\n",
       "  0\n",
       "  1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       "  6\n",
       " -1\n",
       " -1\n",
       " -1\n",
       "  3\n",
       " -1\n",
       " -1\n",
       " -1\n",
       "  4\n",
       "  5\n",
       " [torch.cuda.LongTensor of size 16 (GPU 0)], Variable containing:\n",
       "  20\n",
       "  14\n",
       "  14\n",
       "  20\n",
       "  20\n",
       "  20\n",
       "   4\n",
       "  20\n",
       "  20\n",
       "  20\n",
       "  14\n",
       "  20\n",
       "  20\n",
       "  20\n",
       "  14\n",
       "   4\n",
       " [torch.cuda.LongTensor of size 16 (GPU 0)])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_cls, t_bb = unpad(targ_cls[4],targ_bb[4])\n",
    "match_cat(t_cls,t_bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what was expected as well. Note that here, the ground-truth object with index 2 has no anchor associated to him, which means it has already been attributed to another ground truth object. This won't happen when we have more anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the loss for the predicted classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Write the function that computes the loss between predicted classes and their labels. This is a standard Binary Cross Entropy with one tweak: instead of being one-hot encoded, the background class correspond to a vector of 0 (which means no object was found).\n",
    "\n",
    "**To test:** On the sample 0, we should find 0.3888, and the sample 4, 0.7884"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to one-hot encode our labels ourselves, since we want to treat the background as all zeros. To do this, we first create a regular one-hot encoding with the number of classes plus one, then remove the last column.\n",
    "\n",
    "The .cpu() and .contiguous() are added to please pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels):\n",
    "    lbls = torch.eye(nb_classes+1)[labels.data.cpu()]\n",
    "    return V(lbls[:,:-1].contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 12 \n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     1     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     1     0     0     0     0     0     0     0     0\n",
       "\n",
       "Columns 13 to 19 \n",
       "    0     0     0     0     0     0     0\n",
       "    0     1     0     0     0     0     0\n",
       "    0     1     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0\n",
       "    0     1     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0\n",
       "    0     1     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0\n",
       "[torch.cuda.FloatTensor of size 16x20 (GPU 0)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the loss as a subclass of a nn.Module. It needs to store one parameter: the number of classes. When comparing to our predictions, we also have to remove the column corresponding to the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCELoss(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        t_enc = one_hot(target)\n",
    "        preds = input[:,:-1]\n",
    "        return F.binary_cross_entropy_with_logits(preds,t_enc,size_average=False)/self.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_loss = BCELoss(nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it on our samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.3888\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_cls, t_bb = unpad(targ_cls[0],targ_bb[0])\n",
    "idx,cls = match_cat(t_cls,t_bb)\n",
    "cls_loss(pred_cls[0],cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.7884\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_cls, t_bb = unpad(targ_cls[4],targ_bb[4])\n",
    "idx,cls = match_cat(t_cls,t_bb)\n",
    "cls_loss(pred_cls[4],cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks all good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the loss for the predicted bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** We have to compare each predicted bounding box to the one of the matching grounded object, using the L1 loss. The thing to pay attention to is that the predictions are only relative to the associated anchor.\n",
    "\n",
    "**To test:** We should find 0.1656 for the sample 0 and 0.1239 for the sample 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing is to convert our predictions into the real bbox. The activation for these predictions will be tanh, to have them between -1 and +1. Then the two first activations give the coordinates of the center of our bbox (to scale to the size of our anchor) relatively to the center of the anchor, the second two give the width and height, again scaled to the size of our anchor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 1/4\n",
    "def activ_to_bbox(activ,anc):\n",
    "    activ = F.tanh(activ)\n",
    "    b_ctrs = activ[:,:2] * grid_size/2 + anc[:,:2]\n",
    "    b_sizes = anc[:,2:] * (1 + activ[:,2:] /2)\n",
    "    return cs_to_crnrs(b_ctrs,b_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.0180  0.0281  0.3923  0.3648\n",
       " 0.1880  0.0413  0.5629  0.3693\n",
       " 0.4304  0.0417  0.8054  0.4166\n",
       " 0.6003  0.0101  0.9752  0.3835\n",
       " 0.0160  0.2210  0.3909  0.4547\n",
       " 0.1213  0.2448  0.4963  0.4709\n",
       " 0.3640  0.2109  0.7390  0.5858\n",
       " 0.5752  0.1964  0.9501  0.5708\n",
       "-0.0099  0.5182  0.3650  0.7789\n",
       " 0.1210  0.5704  0.4960  0.6992\n",
       " 0.3913  0.4054  0.7663  0.7738\n",
       " 0.5823  0.4064  0.9570  0.7783\n",
       "-0.0250  0.8021  0.3028  0.9367\n",
       " 0.1607  0.8108  0.4839  0.9370\n",
       " 0.3798  0.7099  0.7510  0.9536\n",
       " 0.6189  0.6956  0.9639  1.0009\n",
       "[torch.cuda.FloatTensor of size 16x4 (GPU 0)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anc_ctsz = torch.cat([anc_ctrs,anc_sz], dim=1)\n",
    "activ_to_bbox(pred_bb[0],anc_ctsz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare the predicted bboxes corresponding to ground truth objects (the one that are associated to background are discarded) and compute the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_loss(p_bb,t_c,t_bb):\n",
    "    idx,cls = match_cat(t_c,t_bb)\n",
    "    p_bb = activ_to_bbox(p_bb,anc_ctsz)\n",
    "    keep = (idx >=0).nonzero()[:,0]\n",
    "    idx[idx==-1]=0\n",
    "    bbs = t_bb[idx]\n",
    "    return torch.abs(p_bb[keep] - bbs[keep]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.1656\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_cls, t_bb = unpad(targ_cls[0],targ_bb[0])\n",
    "bb_loss(pred_bb[0],t_cls,t_bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.1239\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_cls, t_bb = unpad(targ_cls[4],targ_bb[4])\n",
    "bb_loss(pred_bb[4],t_cls,t_bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks all good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the results and sum over a minibatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of efficiency, let's rewrite the function match_cat to do everything in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss1(p_c,p_bb,t_c,t_bb):\n",
    "    t_c,t_bb = unpad(t_c,t_bb)\n",
    "    p_bb = activ_to_bbox(p_bb,anc_ctsz)\n",
    "    overlaps = jaccard(t_bb,anc_crnrs)\n",
    "    over_max,idx_max = overlaps.max(dim=0)\n",
    "    _,forced_idx = overlaps.max(dim=1)\n",
    "    over_max[forced_idx] = 1.1 #Any value greater than 1.\n",
    "    for i,o in enumerate(forced_idx): \n",
    "        idx_max[o] = i\n",
    "    cls = t_c[idx_max]\n",
    "    bbs = t_bb[idx_max]\n",
    "    cls[over_max <= 0.4] = nb_classes\n",
    "    cl_loss = cls_loss(p_c,cls)\n",
    "    keep = (over_max >0.4).nonzero()[:,0]\n",
    "    bb_loss = torch.abs(p_bb[keep] - bbs[keep]).mean()\n",
    "    return cl_loss, bb_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  0.3888\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], Variable containing:\n",
       "  0.1656\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss1(pred_cls[0],pred_bb[0],targ_cls[0],targ_bb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  0.7884\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], Variable containing:\n",
       "  0.1239\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss1(pred_cls[4],pred_bb[4],targ_cls[4],targ_bb[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still looks good! Now we just have to sum over a minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd_loss(pred_c,pred_b,targ_c,targ_b):\n",
    "    l_c, l_b = 0., 0.\n",
    "    for (p_c,p_b,t_c,t_b) in zip(pred_c,pred_b,targ_c,targ_b):\n",
    "        l1c,l1b = loss1(p_c,p_b,t_c,t_b)\n",
    "        l_c += l1c\n",
    "        l_b += l1b\n",
    "    return l_c + l_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 15.6527\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssd_loss(pred_cls,pred_bb,targ_cls,targ_bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mission accomplished!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's add more anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Define all the anchors like in the second part of the notebook and check that everything runs smoothly as well.\n",
    "\n",
    "**To test:** Use the second predicted values, the loss should be 46.0832"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the second mini-batch of predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bb1 = V(np.load(PATH/'pred_bb1.npy'))\n",
    "pred_cls1 = V(np.load(PATH/'pred_cls1.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the anchors augmentation parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc_grids = [4,2,1]\n",
    "anc_zooms = [0.75, 1., 1.3]\n",
    "anc_ratios = [(1.,1.), (1.,0.5), (0.5,1.)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's combine all the possible zooms and ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anc_scales = [(z*rx,z*ry) for z in anc_zooms for (rx,ry) in anc_ratios]\n",
    "k = len(anc_scales)\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to define the new centers and sizes of our anchors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc_ctrs = torch.cat([V(np.repeat(get_anc_ctrs(split),k,axis=0), requires_grad=False) for split in anc_grids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.1250  0.1250\n",
       " 0.1250  0.1250\n",
       " 0.1250  0.1250\n",
       " 0.1250  0.1250\n",
       " 0.1250  0.1250\n",
       " 0.1250  0.1250\n",
       " 0.1250  0.1250\n",
       " 0.1250  0.1250\n",
       " 0.1250  0.1250\n",
       " 0.3750  0.1250\n",
       " 0.3750  0.1250\n",
       " 0.3750  0.1250\n",
       " 0.3750  0.1250\n",
       " 0.3750  0.1250\n",
       " 0.3750  0.1250\n",
       " 0.3750  0.1250\n",
       " 0.3750  0.1250\n",
       " 0.3750  0.1250\n",
       " 0.6250  0.1250\n",
       " 0.6250  0.1250\n",
       " 0.6250  0.1250\n",
       " 0.6250  0.1250\n",
       " 0.6250  0.1250\n",
       " 0.6250  0.1250\n",
       " 0.6250  0.1250\n",
       " 0.6250  0.1250\n",
       " 0.6250  0.1250\n",
       " 0.8750  0.1250\n",
       " 0.8750  0.1250\n",
       " 0.8750  0.1250\n",
       " 0.8750  0.1250\n",
       " 0.8750  0.1250\n",
       " 0.8750  0.1250\n",
       " 0.8750  0.1250\n",
       " 0.8750  0.1250\n",
       " 0.8750  0.1250\n",
       " 0.1250  0.3750\n",
       " 0.1250  0.3750\n",
       " 0.1250  0.3750\n",
       " 0.1250  0.3750\n",
       " 0.1250  0.3750\n",
       " 0.1250  0.3750\n",
       " 0.1250  0.3750\n",
       " 0.1250  0.3750\n",
       " 0.1250  0.3750\n",
       " 0.3750  0.3750\n",
       " 0.3750  0.3750\n",
       " 0.3750  0.3750\n",
       " 0.3750  0.3750\n",
       " 0.3750  0.3750\n",
       " 0.3750  0.3750\n",
       " 0.3750  0.3750\n",
       " 0.3750  0.3750\n",
       " 0.3750  0.3750\n",
       " 0.6250  0.3750\n",
       " 0.6250  0.3750\n",
       " 0.6250  0.3750\n",
       " 0.6250  0.3750\n",
       " 0.6250  0.3750\n",
       " 0.6250  0.3750\n",
       " 0.6250  0.3750\n",
       " 0.6250  0.3750\n",
       " 0.6250  0.3750\n",
       " 0.8750  0.3750\n",
       " 0.8750  0.3750\n",
       " 0.8750  0.3750\n",
       " 0.8750  0.3750\n",
       " 0.8750  0.3750\n",
       " 0.8750  0.3750\n",
       " 0.8750  0.3750\n",
       " 0.8750  0.3750\n",
       " 0.8750  0.3750\n",
       " 0.1250  0.6250\n",
       " 0.1250  0.6250\n",
       " 0.1250  0.6250\n",
       " 0.1250  0.6250\n",
       " 0.1250  0.6250\n",
       " 0.1250  0.6250\n",
       " 0.1250  0.6250\n",
       " 0.1250  0.6250\n",
       " 0.1250  0.6250\n",
       " 0.3750  0.6250\n",
       " 0.3750  0.6250\n",
       " 0.3750  0.6250\n",
       " 0.3750  0.6250\n",
       " 0.3750  0.6250\n",
       " 0.3750  0.6250\n",
       " 0.3750  0.6250\n",
       " 0.3750  0.6250\n",
       " 0.3750  0.6250\n",
       " 0.6250  0.6250\n",
       " 0.6250  0.6250\n",
       " 0.6250  0.6250\n",
       " 0.6250  0.6250\n",
       " 0.6250  0.6250\n",
       " 0.6250  0.6250\n",
       " 0.6250  0.6250\n",
       " 0.6250  0.6250\n",
       " 0.6250  0.6250\n",
       " 0.8750  0.6250\n",
       " 0.8750  0.6250\n",
       " 0.8750  0.6250\n",
       " 0.8750  0.6250\n",
       " 0.8750  0.6250\n",
       " 0.8750  0.6250\n",
       " 0.8750  0.6250\n",
       " 0.8750  0.6250\n",
       " 0.8750  0.6250\n",
       " 0.1250  0.8750\n",
       " 0.1250  0.8750\n",
       " 0.1250  0.8750\n",
       " 0.1250  0.8750\n",
       " 0.1250  0.8750\n",
       " 0.1250  0.8750\n",
       " 0.1250  0.8750\n",
       " 0.1250  0.8750\n",
       " 0.1250  0.8750\n",
       " 0.3750  0.8750\n",
       " 0.3750  0.8750\n",
       " 0.3750  0.8750\n",
       " 0.3750  0.8750\n",
       " 0.3750  0.8750\n",
       " 0.3750  0.8750\n",
       " 0.3750  0.8750\n",
       " 0.3750  0.8750\n",
       " 0.3750  0.8750\n",
       " 0.6250  0.8750\n",
       " 0.6250  0.8750\n",
       " 0.6250  0.8750\n",
       " 0.6250  0.8750\n",
       " 0.6250  0.8750\n",
       " 0.6250  0.8750\n",
       " 0.6250  0.8750\n",
       " 0.6250  0.8750\n",
       " 0.6250  0.8750\n",
       " 0.8750  0.8750\n",
       " 0.8750  0.8750\n",
       " 0.8750  0.8750\n",
       " 0.8750  0.8750\n",
       " 0.8750  0.8750\n",
       " 0.8750  0.8750\n",
       " 0.8750  0.8750\n",
       " 0.8750  0.8750\n",
       " 0.8750  0.8750\n",
       " 0.2500  0.2500\n",
       " 0.2500  0.2500\n",
       " 0.2500  0.2500\n",
       " 0.2500  0.2500\n",
       " 0.2500  0.2500\n",
       " 0.2500  0.2500\n",
       " 0.2500  0.2500\n",
       " 0.2500  0.2500\n",
       " 0.2500  0.2500\n",
       " 0.7500  0.2500\n",
       " 0.7500  0.2500\n",
       " 0.7500  0.2500\n",
       " 0.7500  0.2500\n",
       " 0.7500  0.2500\n",
       " 0.7500  0.2500\n",
       " 0.7500  0.2500\n",
       " 0.7500  0.2500\n",
       " 0.7500  0.2500\n",
       " 0.2500  0.7500\n",
       " 0.2500  0.7500\n",
       " 0.2500  0.7500\n",
       " 0.2500  0.7500\n",
       " 0.2500  0.7500\n",
       " 0.2500  0.7500\n",
       " 0.2500  0.7500\n",
       " 0.2500  0.7500\n",
       " 0.2500  0.7500\n",
       " 0.7500  0.7500\n",
       " 0.7500  0.7500\n",
       " 0.7500  0.7500\n",
       " 0.7500  0.7500\n",
       " 0.7500  0.7500\n",
       " 0.7500  0.7500\n",
       " 0.7500  0.7500\n",
       " 0.7500  0.7500\n",
       " 0.7500  0.7500\n",
       " 0.5000  0.5000\n",
       " 0.5000  0.5000\n",
       " 0.5000  0.5000\n",
       " 0.5000  0.5000\n",
       " 0.5000  0.5000\n",
       " 0.5000  0.5000\n",
       " 0.5000  0.5000\n",
       " 0.5000  0.5000\n",
       " 0.5000  0.5000\n",
       "[torch.cuda.FloatTensor of size 189x2 (GPU 0)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anc_ctrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc_sz = np.concatenate([np.array([[scx/split,scy/split] for i in range(split*split) for (scx,scy) in anc_scales ]) \n",
    "                            for split in anc_grids])\n",
    "anc_sz = V(anc_sz,requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc_crnrs = cs_to_crnrs(anc_ctrs,anc_sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top of those, we used two more variables we have to adapt: anc_ctsz (concatenate the centers and the sizes) and grid_sizes (which was constant before but will now change)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc_ctsz = torch.cat([anc_ctrs,anc_sz], dim=1)\n",
    "grid_size = np.concatenate([np.array([[1/split,1/split] for i in range(split*split) for (scx,scy) in anc_scales ]) \n",
    "                            for split in anc_grids])\n",
    "grid_size = V(grid_size, requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test if we can still call the function activ_to_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.1041 -0.0213  0.1588  0.1319\n",
       " 0.0646  0.1814  0.2809  0.2385\n",
       " 0.0102 -0.0629  0.1337  0.0892\n",
       "-0.0602  0.0995  0.3078  0.2272\n",
       " 0.0984  0.1014  0.2430  0.2193\n",
       " 0.0491 -0.0004  0.1927  0.1261\n",
       "-0.0631  0.0149  0.3970  0.3610\n",
       " 0.0616  0.1317  0.4338  0.2623\n",
       " 0.0744  0.1589  0.3173  0.3308\n",
       " 0.1134 -0.0275  0.3898  0.0700\n",
       " 0.3583  0.2167  0.4736  0.2636\n",
       " 0.1808 -0.0709  0.3213  0.0709\n",
       " 0.1051  0.1185  0.4790  0.2437\n",
       " 0.4176  0.0776  0.5428  0.1527\n",
       " 0.3734 -0.0532  0.5189  0.0718\n",
       " 0.2390  0.0760  0.7262  0.3210\n",
       " 0.2573  0.1949  0.7425  0.2767\n",
       " 0.3560  0.1684  0.5997  0.3312\n",
       " 0.3604 -0.0490  0.6397  0.0522\n",
       " 0.6666  0.2105  0.7757  0.2575\n",
       " 0.4298 -0.0484  0.5704  0.0484\n",
       " 0.3137  0.0910  0.6885  0.2166\n",
       " 0.5761  0.0273  0.7014  0.1030\n",
       " 0.6143 -0.0493  0.8017  0.0757\n",
       " 0.3494  0.1174  0.8368  0.3092\n",
       " 0.4402  0.1773  0.9275  0.2592\n",
       " 0.5751  0.1682  0.8188  0.3307\n",
       " 0.6119 -0.0465  0.8891  0.0759\n",
       " 0.6531  0.1549  0.8953  0.2668\n",
       " 0.6801 -0.0478  0.8205  0.0478\n",
       " 0.5715  0.0319  0.9463  0.1982\n",
       " 0.7033  0.1142  0.8416  0.2806\n",
       " 0.7969  0.0938  0.9799  0.2217\n",
       " 0.5217 -0.0001  1.0075  0.2325\n",
       " 0.5323  0.1835  1.0178  0.2657\n",
       " 0.7382  0.1211  0.9819  0.2871\n",
       "-0.0288  0.4054  0.2432  0.5021\n",
       "-0.0335  0.2811  0.1430  0.3760\n",
       "-0.0521  0.3047  0.0729  0.4051\n",
       "-0.1312  0.2999  0.2332  0.5241\n",
       " 0.0943  0.4567  0.2237  0.5222\n",
       " 0.0827  0.4338  0.2670  0.5590\n",
       "-0.0587  0.2912  0.3901  0.6987\n",
       " 0.0287  0.1663  0.4704  0.3743\n",
       " 0.0629  0.4110  0.2950  0.5761\n",
       " 0.1826  0.3960  0.4630  0.4898\n",
       " 0.2135  0.4161  0.3077  0.4642\n",
       " 0.1798  0.2028  0.3204  0.2972\n",
       " 0.0827  0.3973  0.4493  0.5285\n",
       " 0.4167  0.4675  0.5418  0.5301\n",
       " 0.3951  0.4369  0.5823  0.5619\n",
       " 0.1695  0.3719  0.6566  0.6276\n",
       " 0.2581  0.2349  0.7419  0.3185\n",
       " 0.3559  0.4178  0.5996  0.5803\n",
       " 0.4158  0.2273  0.6970  0.3232\n",
       " 0.4540  0.3349  0.5480  0.3822\n",
       " 0.4303  0.2031  0.5710  0.2969\n",
       " 0.3145  0.4102  0.6856  0.5411\n",
       " 0.4522  0.4684  0.5773  0.5309\n",
       " 0.5207  0.4374  0.7082  0.5624\n",
       " 0.2567  0.4110  0.7439  0.5889\n",
       " 0.3933  0.2125  0.8745  0.3188\n",
       " 0.6004  0.4074  0.8441  0.5699\n",
       " 0.6713  0.2402  0.9521  0.3777\n",
       " 0.6786  0.4031  0.8222  0.5238\n",
       " 0.6807  0.2039  0.8213  0.2980\n",
       " 0.5668  0.4179  0.9345  0.5452\n",
       " 0.6787  0.4606  0.8216  0.5381\n",
       " 0.7012  0.4282  0.8887  0.5701\n",
       " 0.5235  0.4101  0.9766  0.5893\n",
       " 0.5569  0.2289  0.9791  0.3178\n",
       " 0.7101  0.2793  0.9537  0.4419\n",
       "-0.0349  0.5044  0.2404  0.6028\n",
       " 0.1312  0.5254  0.2399  0.6514\n",
       " 0.0212  0.4614  0.0687  0.5564\n",
       "-0.0247  0.5509  0.3374  0.6830\n",
       " 0.1349  0.6323  0.2605  0.7542\n",
       " 0.1229  0.4990  0.2198  0.6241\n",
       " 0.0636  0.4538  0.4349  0.6615\n",
       " 0.1188  0.6015  0.3484  0.7770\n",
       "-0.0244  0.4616  0.1675  0.6286\n",
       " 0.2145  0.4875  0.4957  0.5814\n",
       " 0.3663  0.6915  0.4600  0.7413\n",
       " 0.2271  0.4531  0.2782  0.5469\n",
       " 0.2296  0.4998  0.5888  0.6248\n",
       " 0.4333  0.5907  0.5583  0.6858\n",
       " 0.4154  0.4746  0.5124  0.5996\n",
       " 0.2569  0.4612  0.7431  0.6259\n",
       " 0.3524  0.6722  0.6293  0.7545\n",
       " 0.3030  0.4522  0.5467  0.6147\n",
       " 0.3928  0.4632  0.6741  0.5578\n",
       " 0.4608  0.6868  0.5546  0.7340\n",
       " 0.4336  0.4531  0.5743  0.5469\n",
       " 0.3156  0.5339  0.6895  0.6591\n",
       " 0.4514  0.6453  0.5764  0.7398\n",
       " 0.4623  0.6159  0.6498  0.7409\n",
       " 0.4971  0.4927  0.9837  0.6555\n",
       " 0.3595  0.6760  0.6534  0.7692\n",
       " 0.5087  0.4274  0.7524  0.5899\n",
       " 0.6832  0.5124  0.9644  0.6277\n",
       " 0.7017  0.6866  0.8013  0.7434\n",
       " 0.6817  0.4565  0.8210  0.5504\n",
       " 0.5654  0.5842  0.9387  0.7124\n",
       " 0.6874  0.5668  0.8135  0.7376\n",
       " 0.6975  0.6521  0.8849  0.7850\n",
       " 0.5409  0.6369  0.9706  0.8040\n",
       " 0.6328  0.6411  0.8788  0.7392\n",
       " 0.6876  0.4247  0.9313  0.5873\n",
       "-0.0408  0.8046  0.2385  0.9001\n",
       " 0.1517  0.8578  0.2523  0.9560\n",
       " 0.1896  0.9104  0.2470  1.0055\n",
       "-0.1281  0.7569  0.2378  0.8856\n",
       " 0.1196  0.8167  0.2477  0.9958\n",
       " 0.1654  0.8920  0.2501  1.0205\n",
       " 0.0143  0.6865  0.4722  0.9150\n",
       " 0.1190  0.8273  0.3318  0.9786\n",
       " 0.0313  0.6688  0.1361  0.8388\n",
       " 0.1949  0.8531  0.4762  0.9469\n",
       " 0.4205  0.9391  0.5143  0.9885\n",
       " 0.4481  0.7129  0.5148  0.8068\n",
       " 0.1349  0.7543  0.5044  0.8793\n",
       " 0.4230  0.7365  0.5480  0.9131\n",
       " 0.4373  0.9096  0.5019  1.0347\n",
       " 0.2554  0.6851  0.7427  0.8540\n",
       " 0.3114  0.8988  0.4925  0.9882\n",
       " 0.1906  0.6688  0.4235  0.8314\n",
       " 0.3743  0.8024  0.6556  0.8964\n",
       " 0.5066  0.9480  0.6004  0.9955\n",
       " 0.6763  0.7935  0.8167  0.8873\n",
       " 0.3220  0.8131  0.6952  0.9381\n",
       " 0.4666  0.7676  0.5918  0.9376\n",
       " 0.5517  0.9308  0.7314  1.0561\n",
       " 0.4877  0.6901  0.9747  0.8540\n",
       " 0.4194  0.8708  0.5926  1.0402\n",
       " 0.4398  0.6689  0.6834  0.8314\n",
       " 0.6345  0.8812  0.9151  0.9862\n",
       " 0.7132  0.9439  0.8119  0.9967\n",
       " 0.9012  0.9094  1.0378  1.0039\n",
       " 0.5720  0.9016  0.9399  1.0269\n",
       " 0.6981  0.8176  0.8250  0.9916\n",
       " 0.7559  0.8928  0.9391  1.0272\n",
       " 0.5566  0.7562  1.0116  0.9248\n",
       " 0.6739  0.8287  0.8432  1.0251\n",
       " 0.6910  0.6711  0.9292  0.8338\n",
       " 0.1859  0.1214  0.7479  0.3406\n",
       " 0.2929  0.2401  0.5070  0.4002\n",
       " 0.0407 -0.1057  0.1385  0.1500\n",
       " 0.0947  0.0741  0.8447  0.3737\n",
       " 0.1322  0.2652  0.8506  0.6165\n",
       " 0.1933 -0.0239  0.5678  0.2999\n",
       " 0.0130  0.1146  0.9863  0.6776\n",
       " 0.0213  0.2389  0.9740  0.7195\n",
       " 0.2074  0.0324  0.6943  0.4082\n",
       " 0.4370  0.0970  0.9992  0.5224\n",
       " 0.2643  0.1190  0.7612  0.2151\n",
       " 0.4116  0.0581  0.6850  0.3427\n",
       " 0.3920  0.0695  1.1420  0.6492\n",
       " 0.1867  0.0953  0.9361  0.4552\n",
       " 0.4037  0.3150  0.7746  0.5730\n",
       " 0.1795  0.1424  1.0921  0.7072\n",
       " 0.1204  0.1444  0.9555  0.6288\n",
       " 0.5179 -0.0031  1.0053  0.3390\n",
       "-0.1623  0.5265  0.3990  0.7169\n",
       "-0.0939  0.6468  0.1431  0.7427\n",
       " 0.2676  0.6966  0.4112  0.9227\n",
       " 0.0419  0.5128  0.7913  0.8088\n",
       "-0.1754  0.8575  0.5729  1.0237\n",
       " 0.2514  0.6937  0.6093  0.9851\n",
       " 0.0158  0.1381  0.9832  0.9563\n",
       "-0.0167  0.5475  0.9511  1.0336\n",
       " 0.1662  0.4376  0.6525  0.8673\n",
       " 0.4462  0.5056  1.0080  0.9986\n",
       " 0.3771  0.5381  0.7647  0.6499\n",
       " 0.6497  0.7173  0.8335  1.2743\n",
       " 0.2144  0.2821  0.9577  0.8628\n",
       " 0.1304  0.6493  0.8747  1.0212\n",
       " 0.7801  0.7909  1.1035  1.1331\n",
       " 0.2423  0.2634  1.0824  0.8898\n",
       " 0.1580  0.4018  0.8663  0.8702\n",
       " 0.5054  0.2714  0.9832  0.7738\n",
       " 0.0544  0.1858  0.9816  0.8124\n",
       " 0.0306  0.2545  0.8760  0.7784\n",
       " 0.2056  0.1994  0.7651  0.6952\n",
       " 0.0465  0.1365  0.9695  0.8992\n",
       " 0.1352  0.1339  0.9205  0.8537\n",
       " 0.1421  0.1360  0.8911  0.8827\n",
       " 0.0201  0.1297  0.9107  0.9016\n",
       " 0.0963  0.1041  0.9473  0.9414\n",
       " 0.0562  0.1142  0.9672  0.8884\n",
       "[torch.cuda.FloatTensor of size 189x4 (GPU 0)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activ_to_bbox(pred_bb1[0],anc_ctsz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to work, now ket's check the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 46.0832\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssd_loss(pred_cls1,pred_bb1,targ_cls,targ_bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mission accomplised!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
